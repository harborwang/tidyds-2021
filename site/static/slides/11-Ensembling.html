<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Ensembling</title>
    <meta charset="utf-8" />
    <meta name="author" content="W. Jake Thompson" />
    <meta name="date" content="2021-06-17" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/shareon/shareon.min.css" rel="stylesheet" />
    <script src="libs/shareon/shareon.min.js"></script>
    <link href="libs/xaringanExtra-shareagain/shareagain.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-shareagain/shareagain.js"></script>
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <link href="libs/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <script src="libs/fabric/fabric.min.js"></script>
    <link href="libs/xaringanExtra-scribble/scribble.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-scribble/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#009FB7"],"pen_size":3,"eraser_size":30}) })</script>
    <link href="libs/countdown/countdown.css" rel="stylesheet" />
    <script src="libs/countdown/countdown.js"></script>
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css" integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
    <link rel="stylesheet" href="assets/css/my-theme.css" type="text/css" />
    <link rel="stylesheet" href="assets/css/my-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">









class: title-slide, center

&lt;span class="fa-stack fa-4x"&gt;
  &lt;i class="fa fa-circle fa-stack-2x" style="color: #ffffff;"&gt;&lt;/i&gt;
  &lt;strong class="fa-stack-1x" style="color:#009FB7;"&gt;11&lt;/strong&gt;
&lt;/span&gt; 

# Ensembling

## Tidy Data Science with the Tidyverse and Tidymodels

### W. Jake Thompson

#### [https://tidyds-2021.wjakethompson.com](https://tidyds-2021.wjakethompson.com) &amp;#183; [https://bit.ly/tidyds-2021](https://bit.ly/tidyds-2021)

.footer-license[*Tidy Data Science with the Tidyverse and Tidymodels* is licensed under a [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/).]

&lt;div style = "position:fixed; visibility: hidden"&gt;
  `$$\require{color}\definecolor{blue}{rgb}{0, 0.623529411764706, 0.717647058823529}$$`
  `$$\require{color}\definecolor{light_blue}{rgb}{0.0392156862745098, 0.870588235294118, 1}$$`
  `$$\require{color}\definecolor{yellow}{rgb}{0.996078431372549, 0.843137254901961, 0.4}$$`
  `$$\require{color}\definecolor{dark_yellow}{rgb}{0.635294117647059, 0.47843137254902, 0.00392156862745098}$$`
  `$$\require{color}\definecolor{pink}{rgb}{0.796078431372549, 0.16078431372549, 0.482352941176471}$$`
  `$$\require{color}\definecolor{light_pink}{rgb}{1, 0.552941176470588, 0.776470588235294}$$`
  `$$\require{color}\definecolor{grey}{rgb}{0.411764705882353, 0.403921568627451, 0.450980392156863}$$`
&lt;/div&gt;
  
&lt;script type="text/x-mathjax-config"&gt;
  MathJax.Hub.Config({
    TeX: {
      Macros: {
        blue: ["{\\color{blue}{#1}}", 1],
        light_blue: ["{\\color{light_blue}{#1}}", 1],
        yellow: ["{\\color{yellow}{#1}}", 1],
        dark_yellow: ["{\\color{dark_yellow}{#1}}", 1],
        pink: ["{\\color{pink}{#1}}", 1],
        light_pink: ["{\\color{light_pink}{#1}}", 1],
        grey: ["{\\color{grey}{#1}}", 1]
      },
      loader: {load: ['[tex]/color']},
      tex: {packages: {'[+]': ['color']}}
    }
  });
&lt;/script&gt;

---
class: your-turn

# Your Turn 0

.big[
* Open the R Notebook **materials/exercises/11-ensembling.Rmd**
* Run the setup chunk
]

<div class="countdown" id="timer_60cbb2e1" style="right:0;bottom:0;font-size:2em;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">01</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---
class: center
background-image: url("images/ensembling/tm-hex0.png")
background-position: center 70%
background-size: 90%

# tidymodels

---
class: center
background-image: url("images/ensembling/tm-hex1.png")
background-position: center 70%
background-size: 90%

# tidymodels

---
class: center
background-image: url("images/ensembling/tm-hex2.png")
background-position: center 70%
background-size: 90%

# tidymodels

---
class: center
background-image: url("images/ensembling/tm-hex3.png")
background-position: center 70%
background-size: 90%

# tidymodels

---
class: center
background-image: url("images/ensembling/tm-hex4.png")
background-position: center 70%
background-size: 90%

# tidymodels

---
class: center middle, frame


# To specify a model with parsnip

1\. Pick a .display[model]

2\. Set the .display[engine]

3\. Set the .display[mode] (if needed)

---
class: middle, frame

# .center[To specify a classification tree with parsnip]


```r
decision_tree() %&gt;% 
  set_engine("rpart") %&gt;% 
  set_mode("classification")
```

---
class: your-turn

# Your turn 1

Here is our very-vanilla parsnip model specification for a decision tree (also in your Rmd)...


```r
vanilla_tree_spec &lt;-
  decision_tree() %&gt;% 
  set_engine("rpart") %&gt;% 
  set_mode("classification")
```

---
class: your-turn

# Your turn 1

Fill in the blanks to return the accuracy and ROC AUC for this model.

<div class="countdown" id="timer_60cbb363" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">02</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---
class: your-turn


```r
set.seed(100)
so_folds &lt;- vfold_cv(so_train, strata = remote)

dt_mod &lt;- fit_resamples(vanilla_tree_spec,
                        remote ~ .,
                        resamples = so_folds)

dt_preds &lt;- dt_mod %&gt;%
  collect_metrics()
```




---
# `args()`

.big[Print the arguments for **parsnip** model specification.]


```r
args(decision_tree)
```

---
# `decision_tree()`

.big[Specifies a decision tree model]


```r
decision_tree(tree_depth = 30, min_n = 20, cost_complexity = .01)
```

--

*either* mode works!

---
# `decision_tree()`

.big[Specifies a decision tree model]


```r
decision_tree(
  tree_depth = 30,       # max tree depth
  min_n = 20,            # smallest node allowed
  cost_complexity = .01  # 0 &gt; cp &gt; 0.1
)
```

---
# `set_args()`

.big[Change the arguments for a **parsnip** model specification.]


```r
_spec %&gt;% set_args(tree_depth = 3)
```

---

```r
decision_tree() %&gt;%
  set_engine("rpart") %&gt;%
  set_mode("classification") %&gt;%
* set_args(tree_depth = 3)
#&gt; Decision Tree Model Specification (classification)
#&gt; 
#&gt; Main Arguments:
#&gt;   tree_depth = 3
#&gt; 
#&gt; Computational engine: rpart
```

---

```r
*decision_tree(tree_depth = 3) %&gt;%
  set_engine("rpart") %&gt;%
  set_mode("classification")
#&gt; Decision Tree Model Specification (classification)
#&gt; 
#&gt; Main Arguments:
#&gt;   tree_depth = 3
#&gt; 
#&gt; Computational engine: rpart
```

---
# `tree_depth`

.big[
Cap the maximum tree depth.

A method to stop the tree early. Used to prevent overfitting.
]


```r
vanilla_tree_spec %&gt;% set_args(tree_depth = 30)
#&gt; Decision Tree Model Specification (classification)
#&gt; 
#&gt; Main Arguments:
#&gt;   tree_depth = 30
#&gt; 
#&gt; Computational engine: rpart
```

---
exclude: true



---
&lt;img src="images/ensembling/plots/splits-train-error-1.png" width="90%" style="display: block; margin: auto;" /&gt;

---
&lt;img src="images/ensembling/plots/cp-train-error-1.png" width="90%" style="display: block; margin: auto;" /&gt;

---
&lt;img src="images/ensembling/plots/cp-test-error-1.png" width="90%" style="display: block; margin: auto;" /&gt;

---
# `min_n`

.big[
Set minimum `n` to split at any node.

Another early stopping method. Used to prevent overfitting.
]


```r
vanilla_tree_spec %&gt;% set_args(min_n = 20)
```

---
class: pop-quiz

# Pop quiz!

.big[What value of `min_n` would lead to the *most overfit* tree?]

--

`min_n` = 1

---
class: middle, center, frame

# Recap: early stopping

| `parsnip` arg | `rpart` arg | default | overfit? |
|---------------|-------------|:-------:|:--------:|
| `tree_depth`  | `maxdepth`  |    30   |⬆️|
| `min_n`       | `minsplit`  |    20   |⬇️|

---
# `cost_complexity`

.big[
Adds a cost or penalty to error rates of more complex trees.

A way to prune a tree. Used to prevent overfitting.
]


```r
vanilla_tree_spec %&gt;% set_args(cost_complexity = .01)
#&gt; Decision Tree Model Specification (classification)
#&gt; 
#&gt; Main Arguments:
#&gt;   cost_complexity = 0.01
#&gt; 
#&gt; Computational engine: rpart
```

--

.center[
Closer to zero ➡️ larger trees. 

Higher penalty ➡️ smaller trees. 
]

---

&lt;img src="images/ensembling/plots/cp-test-error2-1.png" width="90%" style="display: block; margin: auto;" /&gt;

---
name: bonsai
background-image: url(images/ensembling/kari-shea-AVqh83jStMA-unsplash.jpg)
background-position: left
background-size: contain
class: middle

---
template: bonsai

.pull-right[

# Consider the bonsai

1. Small pot

1. Strong shears

]

---
template: bonsai

.pull-right[

# Consider the bonsai

1. ~~Small pot~~ .display[Early stopping]

1. ~~Strong shears~~ .display[Pruning]

]

---
class: middle, center, frame

# Recap: early stopping &amp; pruning

| `parsnip` arg | `rpart` arg | default | overfit? |
|---------------|-------------|:-------:|:--------:|
| `tree_depth`  | `maxdepth`  |    30   |⬆️|
| `min_n`       | `minsplit`  |    20   |⬇️|
| `cost_complexity`  | `cp`  |    .01  |⬇️|

---
class: middle, center

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; engine &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; parsnip &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; original &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; rpart &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; tree_depth &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; maxdepth &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; rpart &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; min_n &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; minsplit &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; rpart &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; cost_complexity &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; cp &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;https://rdrr.io/cran/rpart/man/rpart.control.html&gt;

---
class: your-turn

# Your turn 2

Create a new classification tree model spec; call it `big_tree_spec`. Set the cost complexity to `0`, and the minimum number of data points in a node to split to be `1`.

Compare the metrics of the big tree to the vanilla tree. Which one predicts the test set better?

<div class="countdown" id="timer_60cbb32d" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">04</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---
class: your-turn

.panelset[
.panel[.panel-name[Code]

```r
big_tree_spec &lt;-
* decision_tree(min_n = 1, cost_complexity = 0) %&gt;%
  set_engine("rpart") %&gt;%
  set_mode("classification")

set.seed(100) # Important!
big_dt_mod &lt;- fit_resamples(big_tree_spec,
                            remote ~ .,
                            resamples = so_folds)

big_dt_preds &lt;- big_dt_mod %&gt;%
  collect_metrics()
```
]

.panel[.panel-name[Metrics]

```r
big_dt_preds
#&gt; # A tibble: 2 x 6
#&gt;   .metric  .estimator  mean     n std_err .config             
#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
#&gt; 1 accuracy binary     0.590    10  0.0139 Preprocessor1_Model1
#&gt; 2 roc_auc  binary     0.590    10  0.0139 Preprocessor1_Model1
```



Compare to `vanilla`: accuracy = 0.64; ROC AUC = 0.66

]
]

---
exclude: true





---
# The trouble with trees?

&lt;img src="images/ensembling/plots/diff-trees-1.png" width="32%" /&gt;&lt;img src="images/ensembling/plots/diff-trees-2.png" width="32%" /&gt;&lt;img src="images/ensembling/plots/diff-trees-3.png" width="32%" /&gt;

---
# Bootstrapping + decision trees

.big[Back to rainbows and unicorns!]

---
background-image: url(images/ensembling/ensemble/ensemble.001.jpeg)
background-size: cover

---
background-image: url(images/ensembling/ensemble/ensemble.002.jpeg)
background-size: contain

---
background-image: url(images/ensembling/ensemble/ensemble.003.jpeg)
background-size: contain

---
background-image: url(images/ensembling/ensemble/ensemble.004.jpeg)
background-size: contain

---
background-image: url(images/ensembling/ensemble/ensemble.005.jpeg)
background-size: contain

---
background-image: url(images/ensembling/ensemble/ensemble.006.jpeg)
background-size: contain

---
background-image: url(images/ensembling/ensemble/ensemble.007.jpeg)
background-size: contain

---
background-image: url(images/ensembling/ensemble/ensemble.008.jpeg)
background-size: contain

---
background-image: url(images/ensembling/ensemble/ensemble.009.jpeg)
background-size: contain

---
class: middle, frame, center

# Axiom

There is an inverse relationship between  
model *accuracy* and model *interpretability*.

---
exclude: true


```r
plot_tree_resample &lt;- function(rset, id = "Bootstrap01", title = "Sample Variation") {
  lm_train &lt;- function(rset) {
      lm(rainbows ~ unicorns, analysis(rset))
  }
  
  rt_train &lt;- function(rset) {
      rpart::rpart(rainbows ~ unicorns, 
                   data = analysis(rset))
  }
  
  preds &lt;- rset %&gt;% 
      mutate(model = map(splits, lm_train)) %&gt;% 
      mutate(tree = map(splits, rt_train)) %&gt;% 
      mutate(augmented = map(model, augment)) %&gt;% 
      mutate(.fitted_tree = map(tree, predict)) %&gt;% 
      unnest(c(augmented, .fitted_tree))
  
  ggplot(preds, aes(x = unicorns, y = rainbows)) +
      geom_point(size = 3, color = "gray80", alpha = .2) +
      geom_count(data = filter(preds, id == {{ id }}), 
                 color = blue) +
      geom_line(data = filter(preds, id == {{ id }}),
                 aes(x = unicorns, y = .fitted_tree), 
                 colour = pink, size = 2) +
      coord_cartesian(ylim = c(-5, 5), xlim = c(-4, 4)) +
      theme(axis.text.x = element_blank(),
            axis.text.y = element_blank(),
            plot.title = element_text(hjust = 0.5)) + 
      labs(title = title) +
      scale_size_area(max_size = 7, guide = "none")
}

plot_tree_resamples &lt;- function(rset, title = "Sample Variation") {
  lm_train &lt;- function(rset) {
      lm(rainbows ~ unicorns, analysis(rset))
  }
  
  rt_train &lt;- function(rset) {
      rpart::rpart(rainbows ~ unicorns, 
                   data = analysis(rset))
  }
  
  rset %&gt;% 
      mutate(model = map(splits, lm_train)) %&gt;% 
      mutate(tree = map(splits, rt_train)) %&gt;% 
      mutate(augmented = map(model, augment)) %&gt;% 
      mutate(.fitted_tree = map(tree, predict)) %&gt;% 
      unnest(c(augmented, .fitted_tree)) %&gt;% 
    ggplot(aes(unicorns, rainbows)) +
      geom_point(size = 3, color = "gray80") +
      geom_line(aes(y = .fitted_tree, group = id), 
                colour = pink, alpha=.5, size = 2) +
      coord_cartesian(ylim = c(-5, 5), xlim = c(-4, 4)) +
      theme(axis.text = element_blank(),
            plot.title = element_text(hjust = 0.5)) + 
      labs(title = title)
}

get_training &lt;- function(rset, resample = 1) {
  rset %&gt;% 
    pluck("splits", resample) %&gt;% 
    analysis()
}

# make zero correlation variables
set.seed(100)
x &lt;- rnorm(500)

# shuffle x to get y
set.seed(100)
y &lt;- sample(x, size = 500)

# linear combos of x + y
unicorns &lt;- x + y
rainbows &lt;- x - y
cor(unicorns, rainbows)
#&gt; [1] 0.00000000000000000002792251
uni &lt;- tibble(unicorns = unicorns, rainbows = rainbows)

set.seed(1)
sample_1 &lt;- sample_n(uni, 30)

set.seed(1)
boots &lt;- bootstraps(sample_1, times = 25)

set.seed(1)
big_samples &lt;- mc_cv(uni, prop = 0.6, times = 25)

set.seed(1)
big_boots &lt;- bootstraps(get_training(big_samples, 1), times = 25) 
```

---

&lt;img src="images/ensembling/plots/tree-boot-1-1.png" width="90%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="images/ensembling/plots/tree-boot-2-1.png" width="90%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="images/ensembling/plots/tree-boot-3-1.png" width="90%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="images/ensembling/plots/tree-boot-4-1.png" width="90%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="images/ensembling/plots/tree-boot-5-1.png" width="90%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="images/ensembling/plots/tree-boot-all-1.png" width="90%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="images/ensembling/plots/tree-bag-all-1.png" width="90%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="images/ensembling/plots/tree-boot-big-all-1.png" width="90%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="images/ensembling/plots/tree-bag-big-all-1.png" width="90%" style="display: block; margin: auto;" /&gt;

---
# `rand_forest()`

.big[Specifies a random forest model]


```r
rand_forest(mtry = 4, trees = 500, min_n = 1)
```

--

*either* mode works!

---
# `rand_forest()`

.big[Specifies a random forest model]


```r
rand_forest(
  mtry = 4,     # predictors seen at each node
  trees = 500,  # trees per forest
  min_n = 1,    # smallest node allowed
)
```

---
class: your-turn

# Your turn 3

Create a new model spec called `rf_spec`, which will learn an ensemble of classification trees from our training data using the **ranger** package. 

Compare the metrics of the random forest to your two single tree models (vanilla and big)- which predicts the test set better?

*Hint: you'll need https://www.tidymodels.org/find/parsnip/*

<div class="countdown" id="timer_60cbb445" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---
class: your-turn

.panelset[
.panel[.panel-name[Random Forest]

```r
rf_spec &lt;-
  rand_forest() %&gt;%
  set_engine("ranger") %&gt;%
  set_mode("classification")

set.seed(100)
rf_mod &lt;- fit_resamples(rf_spec,
                        remote ~ .,
                        resamples = so_folds)

rf_preds &lt;- rf_mod %&gt;%
  collect_metrics()
```
]

.panel[.panel-name[Performance]

```r
rf_preds
#&gt; # A tibble: 2 x 6
#&gt;   .metric  .estimator  mean     n std_err .config             
#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
#&gt; 1 accuracy binary     0.644    10  0.0132 Preprocessor1_Model1
#&gt; 2 roc_auc  binary     0.704    10  0.0151 Preprocessor1_Model1
```


]

.panel[.panel-name[Comparison]
.pull-left[
.big[**Vanilla Decision Tree**]

```
#&gt; # A tibble: 2 x 3
#&gt;   .metric  .estimator  mean
#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt;
#&gt; 1 accuracy binary     0.642
#&gt; 2 roc_auc  binary     0.657
```


.big[**Big Decision Tree**]

```
#&gt; # A tibble: 2 x 3
#&gt;   .metric  .estimator  mean
#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt;
#&gt; 1 accuracy binary     0.590
#&gt; 2 roc_auc  binary     0.590
```
]

.pull-right[
.big[**Random Forest**]

```
#&gt; # A tibble: 2 x 3
#&gt;   .metric  .estimator  mean
#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt;
#&gt; 1 accuracy binary     0.644
#&gt; 2 roc_auc  binary     0.704
```
]
]
]

---
# `mtry`

.big[The number of predictors that will be randomly sampled at each split when creating the tree models.]


```r
rand_forest(mtry = 4)
```

**ranger** default = `floor(sqrt(num_predictors))`

---
class: your-turn

# Your turn 4

.big[Challenge: make 4 more random forest model specs, each using 4, 8, 12, and 20 variables at each split. Which value maximizes the area under the ROC curve?]

<div class="countdown" id="timer_60cbb29e" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---
class: your-turn

.panelset[
.panel[.panel-name[mtry = 4]

```r
rf4_spec &lt;- rf_spec %&gt;%
  set_args(mtry = 4)

set.seed(100)
fit_resamples(rf4_spec, remote ~ .,
              resample = so_folds) %&gt;%
  collect_metrics()
#&gt; # A tibble: 2 x 6
#&gt;   .metric  .estimator  mean     n std_err .config             
#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
#&gt; 1 accuracy binary     0.644    10  0.0132 Preprocessor1_Model1
#&gt; 2 roc_auc  binary     0.704    10  0.0151 Preprocessor1_Model1
```
]

.panel[.panel-name[mtry = 8]

```r
rf8_spec &lt;- rf_spec %&gt;%
  set_args(mtry = 8)

set.seed(100)
fit_resamples(rf8_spec, remote ~ .,
              resample = so_folds) %&gt;%
  collect_metrics()
#&gt; # A tibble: 2 x 6
#&gt;   .metric  .estimator  mean     n std_err .config             
#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
#&gt; 1 accuracy binary     0.622    10  0.0146 Preprocessor1_Model1
#&gt; 2 roc_auc  binary     0.696    10  0.0138 Preprocessor1_Model1
```
]

.panel[.panel-name[mtry = 12]

```r
rf12_spec &lt;- rf_spec %&gt;%
  set_args(mtry = 12)

set.seed(100)
fit_resamples(rf12_spec, remote ~ .,
              resample = so_folds) %&gt;%
  collect_metrics()
#&gt; # A tibble: 2 x 6
#&gt;   .metric  .estimator  mean     n std_err .config             
#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
#&gt; 1 accuracy binary     0.632    10  0.0116 Preprocessor1_Model1
#&gt; 2 roc_auc  binary     0.690    10  0.0140 Preprocessor1_Model1
```
]

.panel[.panel-name[mtry = 20]

```r
rf20_spec &lt;- rf_spec %&gt;%
  set_args(mtry = 20)

set.seed(100)
fit_resamples(rf20_spec, remote ~ .,
              resample = so_folds) %&gt;%
  collect_metrics()
#&gt; # A tibble: 2 x 6
#&gt;   .metric  .estimator  mean     n std_err .config             
#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
#&gt; 1 accuracy binary     0.620    10  0.0139 Preprocessor1_Model1
#&gt; 2 roc_auc  binary     0.680    10  0.0142 Preprocessor1_Model1
```
]
]

---
class: middle, center



&lt;img src="images/ensembling/plots/mtry-tune-1.png" width="90%" style="display: block; margin: auto;" /&gt;

---

```r
treebag_spec &lt;-
* rand_forest(mtry = .preds()) %&gt;%
  set_engine("ranger") %&gt;% 
  set_mode("classification")

set.seed(100)
fit_resamples(treebag_spec,
              remote ~ ., 
              resamples = so_folds) %&gt;% 
  collect_metrics()
#&gt; # A tibble: 2 x 6
#&gt;   .metric  .estimator  mean     n std_err .config             
#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
#&gt; 1 accuracy binary     0.620    10  0.0139 Preprocessor1_Model1
#&gt; 2 roc_auc  binary     0.680    10  0.0142 Preprocessor1_Model1
```

---
# `.preds()`

.big[The number of columns in the data set that are associated with the predictors prior to dummy variable creation.]


```r
rand_forest(mtry = .preds())
```

---
.pull-left[

.big[**Vanilla Decision Tree**]

```
#&gt; # A tibble: 2 x 3
#&gt;   .metric  .estimator  mean
#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt;
#&gt; 1 accuracy binary     0.642
#&gt; 2 roc_auc  binary     0.657
```

.big[**Big Decision Tree**]

```
#&gt; # A tibble: 2 x 3
#&gt;   .metric  .estimator  mean
#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt;
#&gt; 1 accuracy binary     0.590
#&gt; 2 roc_auc  binary     0.590
```
]

.pull-right[
.big[**Random Forest**]

```
#&gt; # A tibble: 2 x 3
#&gt;   .metric  .estimator  mean
#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt;
#&gt; 1 accuracy binary     0.644
#&gt; 2 roc_auc  binary     0.704
```

.big[**Bagging**]

```
#&gt; # A tibble: 2 x 6
#&gt;   .metric  .estimator  mean     n std_err .config             
#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
#&gt; 1 accuracy binary     0.620    10  0.0139 Preprocessor1_Model1
#&gt; 2 roc_auc  binary     0.680    10  0.0142 Preprocessor1_Model1
```
]

---
class: middle, frame

# .center[To specify a model with parsnip]

.right-column[

.fade[

1\. Pick a .display[model]

]

2\. Set the .display[engine]

.fade[

3\. Set the .display[mode] (if needed)
]
]

---
# `set_engine()`

Adds to a model an R package to train the model.


```r
spec %&gt;% set_engine(engine = "ranger", ...)
```

---
# `set_engine()`

Adds to a model an R package to train the model.


```r
spec %&gt;% 
  set_engine(
    engine = "ranger", # package name in quotes
    ...                # optional arguments to pass to function
    )
```

---
.fade[

# `set_engine()`

Adds to a model an R package to train the model.
]



```r
rf_imp_spec &lt;-
  rand_forest(mtry = 4) %&gt;% 
  set_engine("ranger", importance = "impurity") %&gt;% 
  set_mode("classification")
```

---

```r
rf_imp_spec &lt;-
  rand_forest(mtry = 4) %&gt;% 
  set_engine("ranger", importance = 'impurity') %&gt;% 
  set_mode("classification")

imp_fit &lt;- fit(rf_imp_spec,
               remote ~ .,
               data = so_train) 
```

---

```r
imp_fit
#&gt; parsnip model object
#&gt; 
#&gt; Fit time:  252ms 
#&gt; Ranger result
#&gt; 
#&gt; Call:
#&gt;  ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~4,      x), importance = ~"impurity", num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1), probability = TRUE) 
#&gt; 
#&gt; Type:                             Probability estimation 
#&gt; Number of trees:                  500 
#&gt; Sample size:                      864 
#&gt; Number of independent variables:  20 
#&gt; Mtry:                             4 
#&gt; Target node size:                 10 
#&gt; Variable importance mode:         impurity 
#&gt; Splitrule:                        gini 
#&gt; OOB prediction error (Brier s.):  0.2204509
```

---
# `vip`

.big[Plot variable importance]

.center[
&lt;iframe src="https://koalaverse.github.io/vip/index.html" width="80%" height="400px"&gt;&lt;/iframe&gt;
]

---
# `vip()`

.big[Plot variable importance scores for the predictors in a model.]


```r
vip(object, geom = "point", ...)
```

---
# `vip()`

.big[Plot variable importance scores for the predictors in a model.]


```r
vip(object,          # fitted model object
    geom = "point",  # one of "col", "point", "boxplot", "violin"
    ...
    )
```

---

```r
vip(imp_fit, geom = "point")
```

&lt;img src="images/ensembling/plots/imp-plot-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---
class: your-turn

# Your turn 5

Make a new model spec called `treebag_imp_spec` to fit a bagged classification tree model. Set the variable `importance` mode to "permutation". Plot the variable importance- which variable was the most important?

<div class="countdown" id="timer_60cbb1fc" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---
class: your-turn

.panelset[
.panel[.panel-name[Code]

```r
treebag_imp_spec &lt;-
  rand_forest(mtry = .preds()) %&gt;% 
  set_engine("ranger", importance = "permutation") %&gt;% 
  set_mode("classification")

imp_fit &lt;- 
  fit(treebag_imp_spec,
      remote ~ ., 
      data = so_train) 

vip(imp_fit)
```
]

.panel[.panel-name[Plot]
&lt;img src="images/ensembling/plots/treebag-vip-1.png" width="80%" style="display: block; margin: auto;" /&gt;
]
]

---
class: title-slide, center

# Ensembling

&lt;img src="images/ensembling/hex-group.png" width="18%" style="display: block; margin: auto;" /&gt;

## Tidy Data Science with the Tidyverse and Tidymodels

### W. Jake Thompson

#### [https://tidyds-2021.wjakethompson.com](https://tidyds-2021.wjakethompson.com) &amp;#183; [https://bit.ly/tidyds-2021](https://bit.ly/tidyds-2021)

.footer-license[*Tidy Data Science with the Tidyverse and Tidymodels* is licensed under a [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/).]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "solarized-light",
"highlightLanguage": ["r", "css", "yaml"],
"slideNumberFormat": "",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
