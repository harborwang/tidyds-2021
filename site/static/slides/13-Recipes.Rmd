---
title: "Feature Engineering"
subtitle: "Tidy Data Science with the Tidyverse and Tidymodels"
session: 13
author: W. Jake Thompson
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: ["default", "assets/css/my-theme.css", "assets/css/my-fonts.css"]
    seal: false 
    lib_dir: libs
    nature:
      # autoplay: 5000
      highlightStyle: solarized-light
      highlightLanguage: ["r", "css", "yaml"]
      slideNumberFormat: "" 
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      beforeInit: "https://platform.twitter.com/widgets.js"
    includes:
      in_header: [assets/header.html]
params:
  site_link: "https://bit.ly/tidyds-2021"
  class_link: "https://tidyds-2021.wjakethompson.com"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(collapse = TRUE,
                      fig.retina = 3,
                      fig.path = "images/recipes/plots/",
                      fig.align = "center",
                      fig.asp = 0.618,
                      comment = "#>")

xaringanExtra::use_share_again()
xaringanExtra::use_panelset()
xaringanExtra::use_extra_styles(hover_code_line = TRUE,
                                mute_unhighlighted_code = FALSE)
xaringanExtra::use_scribble(pen_color = "#009FB7")

yt_counter <- 0
library(countdown)
library(tidyverse)
library(tidymodels)
library(flair)
library(here)
library(knitr)
library(downlit)
library(vip)
library(themis)

library(xaringancolor)
blue <- "#009FB7"
light_blue <- "#0ADEFF"
yellow <- "#FED766"
dark_yellow <- "#A27A01"
pink <- "#CB297B"
light_pink <- "#FF8DC6"
green <- "#5FAD56"
dark_green <- "#3C6E35"
grey <- "#696773"

library(AmesHousing)
ames <- make_ames()

lm_spec <- 
  linear_reg() %>% 
  set_engine("lm") %>% 
  set_mode("regression")

set.seed(100) # Important!
ames_split  <- initial_split(ames)
ames_train  <- training(ames_split)
ames_test   <- testing(ames_split)

set.seed(100)
ames_folds <- vfold_cv(ames_train)

theme_set(wjake::theme_wjake(base_family = "Source Sans Pro",
                             base_size = 14,
                             axis_title_size = 12))
```


class: title-slide, center

<span class="fa-stack fa-4x">
  <i class="fa fa-circle fa-stack-2x" style="color: #ffffff;"></i>
  <strong class="fa-stack-1x" style="color:#009FB7;">`r rmarkdown::metadata$session`</strong>
</span> 

# `r rmarkdown::metadata$title`

## `r rmarkdown::metadata$subtitle`

### `r rmarkdown::metadata$author`

#### [`r params$class_link`](`r params$class_link`) &#183; [`r params$site_link`](`r params$site_link`)

.footer-license[*Tidy Data Science with the Tidyverse and Tidymodels* is licensed under a [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/).]

<div style = "position:fixed; visibility: hidden">
  $$\require{color}\definecolor{blue}{rgb}{0, 0.623529411764706, 0.717647058823529}$$
  $$\require{color}\definecolor{light_blue}{rgb}{0.0392156862745098, 0.870588235294118, 1}$$
  $$\require{color}\definecolor{yellow}{rgb}{0.996078431372549, 0.843137254901961, 0.4}$$
  $$\require{color}\definecolor{dark_yellow}{rgb}{0.635294117647059, 0.47843137254902, 0.00392156862745098}$$
  $$\require{color}\definecolor{pink}{rgb}{0.796078431372549, 0.16078431372549, 0.482352941176471}$$
  $$\require{color}\definecolor{light_pink}{rgb}{1, 0.552941176470588, 0.776470588235294}$$
  $$\require{color}\definecolor{grey}{rgb}{0.411764705882353, 0.403921568627451, 0.450980392156863}$$
</div>
  
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      Macros: {
        blue: ["{\\color{blue}{#1}}", 1],
        light_blue: ["{\\color{light_blue}{#1}}", 1],
        yellow: ["{\\color{yellow}{#1}}", 1],
        dark_yellow: ["{\\color{dark_yellow}{#1}}", 1],
        pink: ["{\\color{pink}{#1}}", 1],
        light_pink: ["{\\color{light_pink}{#1}}", 1],
        grey: ["{\\color{grey}{#1}}", 1]
      },
      loader: {load: ['[tex]/color']},
      tex: {packages: {'[+]': ['color']}}
    }
  });
</script>

---
class: your-turn

# Your Turn 0

.big[
* Open the R Notebook **materials/exercises/13-recipes.Rmd**
* Run the setup chunk
]

```{r yt-setwd-cd, echo = FALSE}
countdown(minutes = 1, seconds = 0,
          font_size = "2em",
          color_border = yellow,
          color_background = blue,
          color_text = yellow,
          color_running_background = "#F0F0F0",
          color_running_text = blue,
          color_finished_background = yellow,
          color_finished_text = blue)
```

---
<div class="hex-book">
  <a href="https://recipes.tidymodels.org">
    <img class="hex" src="images/hex/recipes.png">
  </a>
  <a href="https://www.tmwr.org/recipes.html">
    <img class="book" src="images/books/tmwr-recipes.png">
  </a>
</div>

---
background-image: url(images/recipes/wf-12.png)
background-position: center 85%
background-size: 70%

# Machine Learning

---
class: center
background-image: url(images/recipes/tidymodels/tm-01.png)
background-position: center 70%
background-size: 90%

# tidymodels

---
class: center
background-image: url(images/recipes/tidymodels/tm-02.png)
background-position: center 70%
background-size: 90%

# tidymodels

---
class: center
background-image: url(images/recipes/tidymodels/tm-03.png)
background-position: center 70%
background-size: 90%

# tidymodels

---
class: center
background-image: url(images/recipes/tidymodels/tm-04.png)
background-position: center 70%
background-size: 90%

# tidymodels

---
class: center
background-image: url(images/recipes/tidymodels/tm-05.png)
background-position: center 70%
background-size: 90%

# tidymodels

---
class: center
background-image: url(images/recipes/tidymodels/tm-06.png)
background-position: center 70%
background-size: 90%

# tidymodels

---
class: pop-quiz

# Pop quiz!

What is multicollinearity?

--

When multiple predictors are strongly correlated. It can impair linear models.

---
# Principle Components Analysis

Transforms variables into the orthogonal "components" that most concisely capture all of the variation.

```{r include=FALSE}
uni_train <- iris %>% 
  janitor::clean_names() %>% 
  mutate(unicorn = as.factor(if_else(species == "versicolor", 1, 0))) %>% 
  mutate(across(starts_with("sepal"), ~(.x * 10))) %>% 
  select(n_butterflies = sepal_width, n_kittens = sepal_length, unicorn)
```

```{r pr-plot, echo=FALSE, warning=FALSE, message=FALSE, out.width='65%'}
library(ggfortify)
df <- uni_train[c(1, 2)]

autoplot(prcomp(df), data = uni_train, size = 4, alpha = .8, colour = 'unicorn',
         loadings = TRUE, loadings.colour = 'black',
         loadings.label = TRUE, loadings.label.size = 8,
         loadings.label.colour = "black",
         loadings.label.family = "Source Sans Pro",
         loadings.label.repel = TRUE) +
  scale_colour_manual(values = c(blue, pink), guide = "none")
```

---
class: middle, center, frame

# Goal

To fit a linear model to the main Principal Components of the `ames` data.

---
# To build a recipe

1\. Start the `recipe()`

2\. Define the .display[variables] involved

3\. Describe **prep**rocessing .display[step-by-step]

---
# `recipe()`

Creates a recipe for a set of variables.

```{r eval = FALSE}
recipe(Sale_Price ~ ., data = ames)
```

---
# `step_*()`

Adds a single transformation to a recipe. Transformations are replayed in order when the recipe is run on data.

```{r rec-example, eval = FALSE}
rec %>%
  step_novel(all_nominal()) %>%
  step_zv(all_predictors())
```

---
# `step_*()`

Complete list at: https://recipes.tidymodels.org/reference/index.html

```{r echo = FALSE, out.width = "85%"}
include_url("https://recipes.tidymodels.org/reference/index.html")
```

---
# Selectors

Helper functions fro selecting sets of variables.

```{r echo = FALSE}
decorate("rec-example", eval = FALSE) %>%
  flair("all_nominal()", background = yellow, color = blue) %>%
  flair("all_predictors()", background = yellow, color = blue)
```

---
class: middle

```{r include=FALSE}
all <- tribble(
  ~ selector, ~ description,
  "`all_predictors()`", "Each x variable  (right side of ~)",
  "`all_outcomes()`", "Each y variable  (left side of ~)",
  "`all_numeric()`", "Each numeric variable",
  "`all_nominal()`", "Each categorical variable (e.g. factor, string)",
  "`dplyr::select()` helpers", "`starts_with('Lot_')`, etc."
)
```

```{r echo=FALSE, warning = FALSE, out.width='90%'}
library(gt)
gt(all)  %>%
  fmt_markdown(columns = TRUE) %>%
  tab_options(
    table.width = pct(10),
    table.font.size = "200px"
  ) %>%
  wjake::gt_theme_wjake() %>%
  gt::cols_width(vars(selector) ~ px(400),
                 vars(description) ~ px(500))
```

---
# Combining selectors

Use commas to separate

```{r eval = FALSE}
rec %>%
  step_novel(all_nominal(), -all_outcomes()) %>% #<<
  step_zv(all_predictors())
```

---
class: pop-quiz

# Pop quiz!

How does recipes know what is a **predictor** and what is an **outcome**?

--

```{r}
rec <- 
  recipe(Sale_Price ~ ., #<<
         data = ames)
```

--

The .display[formula] `r emo::ji("right_arrow")`  *indicates outcomes vs predictors*

---
class: pop-quiz

# Pop quiz!

How does recieps know what is **numeric** and what is **nominal**?

--

```{r}
rec <- 
  recipe(Sale_Price ~ .,
         data = ames) #<<
```

--

The .display[data] `r emo::ji("right_arrow")`  *is only used to catalog the names and types of each variable*

---
class: pop-quiz

# Pop quiz!

PCA requires variables to be **centered** and **scaled**. What does that mean?

--

Standardize or *z*-score

---
# `step_center()`

Centers numeric variables by subtracting the mean

```{r}
rec <-
  recipe(Sale_Price ~ .,
         data = ames) %>%
  step_center(all_numeric()) #<<
```

---
# `step_scale()`

Scales numeric variables by dividing by the standard deviation

```{r}
rec <-
  recipe(Sale_Price ~ .,
         data = ames) %>%
  step_center(all_numeric()) %>%
  step_scale(all_numeric()) #<<
```

---
class: pop-quiz

# Pop quiz!

Why do you need to "train" a recipe?

--

Imagine "scaling" a new data point. What do you subtract from it? What do you divide it by?

---
background-image: url(images/recipes/prep-recipe.png)
background-position: center middle
background-size: 90%

---
background-image: url(images/recipes/bake-recipe.png)
background-position: center middle
background-size: 90%

---
# `prep()` and `bake()`

"trains" a recipe and then transforms data with the prepped recipe

```{r eval = FALSE}
rec %>%
  prep(training = ames_train) %>%
  bake(new_data = ames_test) # or ames train
```

--

.footnote[.display[You don't need to do this! The fit functions do it for you]]

---
background-image: url(images/recipes/recipes.png)
background-size: cover

.footnote[Artwork by [@allison_horst](https://twitter.com/allison_horst)]

---
```{r include=FALSE}
rec <- 
  recipe(Sale_Price ~ ., 
         data = ames) %>% 
  step_center(all_numeric()) %>% 
  step_scale(all_numeric()) 
```

```{r}
rec %>% 
  prep(ames_train) %>%
  bake(ames_test) 
```

---
class: pop-quiz

# Pop quiz!

.left-column[
```{r echo=FALSE, comment = NA}
ames %>%
  distinct(Roof_Style)
```
]

.right-column[
```{r echo=FALSE, comment = NA}
ames %>% 
  select(Roof_Style) %>% 
  mutate(val = 1, home = dplyr::row_number()) %>% 
  pivot_wider(id_col = home, 
              names_from = Roof_Style, 
              values_from = val, 
              values_fill = list(val = 0)) %>% 
  select(-home)
```
]

---
# Dummy Variables

```{r results='hide'}
lm(Sale_Price ~ Roof_Style, data = ames)
```

```{r echo=FALSE}
lm(Sale_Price ~ Roof_Style, data = ames) %>% 
  broom::tidy()
```

---
# `step_dummy()`

Converts nominal data into dummy variables which are numeric and suitable for linear algebra.

```{r eval = FALSE}
rec %>%
  step_dummay(all_nominal()) #<<
```

.footnote[You don't need this for decision trees or ensembles of trees]

---
class: pop-quiz

# Consider

Let's think about the modeling.

What if there were no homes with shed roofs in the training data?

--

Will the model have a coefficient for shed roof?

--

.display[No]

--

What will happen if the test data has a home with a shed roof?

--

.display[Error!]

---
# `step_novel()`

Adds a catch-all level to a factor for any new values, which lets R intelligently predict new levels in the test set.

```{r eval = FALSE}
rec %>%
  step_novel(all_nominal()) %>% #<<
  step_dummy(all_nominal())
```

.footnote[Use *before* `step_dummy()` so new level is dummified]

---
class: pop-quiz

# Consider

What would happen if you try to scale a variable that doesn't vary?

--

.display[Error!] You'd be dividing by zero!

---
# `step_zv()`

Intelligently handles zero variance variables (variables that contain only a single value)

```{r eval = FALSE}
rec %>%
  step_novel(all_nominal()) %>%
  step_dummy(all_nominal()) %>%
  step_zv(all_predictors()) #<<
```

---
class: pop-quiz

# Pop quiz!

What step function would do PCA?

--

```{r echo = FALSE, out.width = "95%"}
include_url("https://recipes.tidymodels.org/reference/step_pca.html")
```

---
# `step_pca()`

Replaces variables with components

```{r eval = FALSE}
rec %>%
  step_pca(all_numeric(),
           num_comp = 5) #<<
```

---
class: your-turn

# Your Turn `r (yt_counter <- yt_counter + 1)`

Write a recipe for the `Sale_Price ~ .` variables that:

1. Adds a novel level to all factors
1. Converts all factors to dummy variables
1. Catches any zero variance variables
1. Centers all of the predictors
1. Scales all of the predictors
1. Computes the first 5 principal components

Save the result as `pca_rec`

```{r echo=FALSE}
countdown(minutes = 5)
```

---
class: your-turn

.panelset[
.panel[.panel-name[Code]
```{r}
pca_rec <- 
  recipe(Sale_Price ~ ., data = ames) %>%
  step_novel(all_nominal()) %>%
  step_dummy(all_nominal()) %>%
  step_zv(all_predictors()) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>%
  step_pca(all_predictors(), num_comp = 5)
```
]

.panel[.panel-name[Recipe]
```{r}
pca_rec
```
]
]

---
# Roles

You can also give variables a "role" within a recipe and then select by roles.

```{r results='hide', warning=FALSE, message=FALSE}
has_role(match = "privacy")
add_role(rec, Fence, new_role = "privacy")
update_role(rec, Fence, new_role = "privacy", old_role = "yard")
remove_role(rec, Fence, old_role = "yard")
```

---
class: pop-quiz

# Pop quiz!

If we use `add_model()` to add a model to a workflow, what would we use to add a recipe?

--

Let's see!

---
class: your-turn

# Your Turn `r (yt_counter <- yt_counter + 1)`

Make a workflow that combines `pca_rec` and with `lm_spec`.

```{r echo=FALSE}
countdown(minutes = 2)
```

---
class: your-turn

.panelset[
.panel[.panel-name[Code]
```{r}
pca_wf <-
  workflow() %>%
  add_recipe(pca_rec) %>%
  add_model(lm_spec)
```
]

.panel[.panel-name[Workflow]
```{r}
pca_wf
```
]
]

---
# `add_recipe()`

Adds a recipe to a workflow.

```{r eval = FALSE}
pca_wf <-
  workflow() %>%
  add_recipe(pca_rec) %>% #<<
  add_model(lm_spec)
```

---
class: pop-quiz

# Pop quiz!

Do you need to add a formula if you have a recipe?

--

Nope!

```{r eval = FALSE}
rec <-
  recipe(Sale_Price ~ ., #<<
         data = ames)
```

---
class: your-turn

# Your Turn `r (yt_counter <- yt_counter + 1)`

Try our PCA workflow on `ames_folds`. What is the estimated RMSE?

```{r echo = FALSE}
countdown(minutes = 4)
```

---
class: your-turn

```{r fit-pca, cache = TRUE}
pca_wf %>%
  fit_resamples(resamples = ames_folds) %>%
  collect_metrics()
```

---
# `update_recipe()`

Replace the recipe in a workflow.

```{r eval = FALSE}
pca_wf %>%
  update_recipe(bc_rec) #<<
```

---
class: your-turn

# Your Turn `r (yt_counter <- yt_counter + 1)`

Modify the code to build a new PCA recipe that uses a BoxCox transformation instead of centering and scaling the data. 

Then update `pca_wf` to use the new recipe.

*Hint: Guess. Use tab completion. Or visit https://recipes.tidymodels.org/reference/index.html.*

```{r echo=FALSE}
countdown(minutes = 3)
```

---
class: your-turn

```{r}
bc_rec <-
  recipe(Sale_Price ~ ., data = ames) %>%
  step_novel(all_nominal()) %>%
  step_dummy(all_nominal()) %>%
  step_zv(all_predictors()) %>%
  step_BoxCox(all_predictors()) %>% #<<
  step_pca(all_predictors(), num_comp = 5)

bc_wf <- 
  pca_wf %>%
  update_recipe(bc_rec)
```

---
```{r fit-bc, cache = TRUE}
bc_wf %>%
  fit_resamples(resamples = ames_folds) %>%
  collect_metrics()
```

---
class: middle, center

# Feature Engineering

.pull-left[
Before

![](https://media.giphy.com/media/Wn74RUT0vjnoU98Hnt/giphy.gif)
]

--

.pull-right[
After

![](https://media.giphy.com/media/26tPgV8ceZTSxH9zG/giphy.gif)
]

---
# StackOverflow Data

```{r}
library(modeldata)
data(stackoverflow)
```

```{r}
glimpse(stackoverflow)
```

???

Bigger version of what we used earlier.

---
class: pop-quiz

# Pop quiz!

Name that package!

```{r}
set.seed(100) # Important!
so_split <- initial_split(stackoverflow, strata = Remote)
so_train <- training(so_split)
so_test  <- testing(so_split)
```

--

```{r echo = FALSE, fig.align='center', out.width = "20%"}
include_graphics("images/hex/rsample.png")
```


---
class: pop-quiz

# Pop quiz!

Name that package!

```{r}
tree_spec <- 
  decision_tree() %>%         
  set_engine("rpart") %>%      
  set_mode("classification")
```

--

```{r echo = FALSE, fig.align='center', out.width = "20%"}
include_graphics("images/hex/parsnip.png")
```

---
class: pop-quiz

# Pop quiz!

Name that package!

```{r}
so_rec <- recipe(Remote ~ ., data = so_train) %>% 
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  step_lincomb(all_predictors())
```

--

```{r echo = FALSE, fig.align='center', out.width = "20%"}
include_graphics("images/hex/recipes.png")
```

---
class: pop-quiz

# Pop quiz!

Name that package!

```{r}
so_wf <- workflow() %>% 
  add_model(tree_spec) %>% 
  add_recipe(so_rec)
```

--

```{r echo = FALSE, fig.align='center', out.width = "20%"}
include_graphics("images/hex/workflows.png")
```

---
# `fit()`

```{r}
set.seed(1980)

so_fit <- so_wf %>%
  fit(data = so_train)

so_preds <- bind_cols(
  predict(so_fit, new_data = so_test, type = "class"),
  predict(so_fit, new_data = so_test, type = "prob")
) %>%
  mutate(truth = so_test$Remote)

so_metric_set <- metric_set(accuracy, roc_auc)
so_metric_set(so_preds, truth = truth, .pred_Remote, estimate = .pred_class)
```

---
```{r}
so_metric_set <- metric_set(accuracy, roc_auc, sens, spec)
so_metric_set(so_preds, truth = truth, .pred_Remote, estimate = .pred_class)
```

---
class: pop-quiz

# Pop quiz!

Can you guess what the confusion matrix looks like?

--

.left-column[
## uh oh
]

.right-column[
```{r}
conf_mat(so_preds, truth = truth, estimate = .pred_class)
```
]

---
class: pop-quiz

# Pop quiz!

Can you guess what the confusion matrix looks like?

.left-column[
## uh oh
]

.right-column[
```{r uh-oh-roc, echo = FALSE, fig.asp = NA, out.width = "50%"}
roc_curve(so_preds, truth = truth, estimate = .pred_Remote) %>%
  autoplot()
```
]

---
```{r}
so_train %>%
  count(Remote)

so_test %>%
  count(Remote)
```

---
class: center middle inverse

# How can we get better at identifying the less frequent class?

--

Sub-class sampling

---
# Downsampling

.pull-left[
```{r uni-biscatter, echo=FALSE, fig.asp = NA, out.width = "100%"}
ggplot(uni_train, aes(x = n_kittens, y = n_butterflies, color = unicorn)) +
  geom_point(alpha = .8, size = 4) +
  scale_colour_manual(values = c(blue, pink), guide = "none") +
  labs(x = NULL, y = NULL)
```
]

--

.pull-right[
```{r uni-downsamp, echo=FALSE, fig.asp = NA, out.width = "100%"}
uni_down_rec <- recipe(unicorn ~ ., data = uni_train) %>% 
  step_downsample(all_outcomes())

uni_down <- uni_down_rec %>% 
  prep(training = uni_train, 
       retain = TRUE) %>% 
  juice()

ggplot(uni_down, aes(x = n_kittens, y = n_butterflies, color = unicorn)) +
  geom_point(data = filter(uni_down, unicorn == 1), alpha = .8, size = 4) +
  geom_count(data = filter(uni_down, unicorn == 0), alpha = .8) +
  scale_colour_manual(values = c(blue, pink), guide = "none") +
  labs(x = NULL, y = NULL) +
  scale_size_area(max_size = 8, guide = "none")
```
]

---
# Upsampling

.pull-left[
```{r uni-biscatter2, ref.label="uni-biscatter", echo=FALSE, fig.asp = NA, out.width = "100%"}
```
]

--

.pull-right[
```{r uni-upsamp, echo=FALSE, fig.asp = NA, out.width = "100%"}
uni_up_rec <- recipe(unicorn ~ ., data = uni_train) %>% 
  step_upsample(all_outcomes())

uni_up <- uni_up_rec %>% 
  prep(training = uni_train, 
       retain = TRUE) %>% 
  juice()

ggplot(uni_up, aes(x = n_kittens, y = n_butterflies, color = unicorn)) +
  geom_count(data = filter(uni_up, unicorn == 1), alpha = .8, size = 4) +
  geom_count(data = filter(uni_up, unicorn == 0), alpha = .8) +
  scale_colour_manual(values = c(blue, pink), guide = "none") +
  labs(x = NULL, y = NULL) +
  scale_size_area(max_size = 8, guide = "none")
```
]

---
class: your-turn

# Your Turn `r (yt_counter <- yt_counter + 1)`

Add a recipe step to downsample the remote variable majority class in the training set prior to model training. Edit your workflow, then re-fit the model and examine the metrics. Is the ROC AUC better than chance (.5)?

```{r echo=FALSE}
countdown(minutes = 5)
```

---
class: your-turn

.panelset[
.panel[.panel-name[Fit Workflow]
```{r}
so_down <- recipe(Remote ~ ., data = so_train) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_lincomb(all_predictors()) %>%
  step_downsample(all_outcomes()) #<<

so_downwf <- so_wf %>%
  update_recipe(so_down) #<<

set.seed(1980)
so_downfit <- so_downwf %>%
  fit(data = so_train)

so_downpreds <- bind_cols(
  predict(so_downfit, new_data = so_test, type = "class"),
  predict(so_downfit, new_data = so_test, type = "prob")
) %>%
  mutate(truth = so_test$Remote)
```
]

.panel[.panel-name[Workflow Metrics]
```{r}
so_metric_set(so_downpreds, truth = truth, .pred_Remote, estimate = .pred_class)
```
]
]

---
.left-column[
## Ahh!
]

.right-column[
```{r ahh-roc, echo = FALSE, fig.asp = NA, out.width = "70%"}
roc_curve(so_downpreds, truth = truth, estimate = .pred_Remote) %>%
  autoplot()
```
]

---
# `juice()`

Get the preprocessed training data back from a prepped recipe. Returns a tibble.

```{r eval = FALSE}
so_down %>%
  prep(training = so_train) %>%
  juice()
```

---
# Downsampling

.pull-left[
```{r}
so_train %>%
  count(Remote)
```
]

--

.pull-right[
```{r}
so_down %>%
  prep(training = so_train) %>%
  juice() %>% #<<
  count(Remote)
```
]

---
# `step_downsample()`

Down-sampling is performed on the training set *only*. Default is `skip = TRUE`.

.pull-left[
```{r}
so_test %>%
  count(Remote)
```
]

--

.pull-right[
```{r}
so_down %>%
  prep(training = so_train) %>%
  bake(new_data = so_test) %>%
  count(Remote)
```
]

---
class: title-slide, center

# `r rmarkdown::metadata$title`

```{r closing-hex, echo = FALSE, out.width = "20%"}
include_graphics("images/hex/recipes.png")
```

## `r rmarkdown::metadata$subtitle`

### `r rmarkdown::metadata$author`

#### [`r params$class_link`](`r params$class_link`) &#183; [`r params$site_link`](`r params$site_link`)

.footer-license[*Tidy Data Science with the Tidyverse and Tidymodels* is licensed under a [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/).]
