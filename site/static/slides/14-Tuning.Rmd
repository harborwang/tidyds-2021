---
title: "Model Tuning"
subtitle: "Tidy Data Science with the Tidyverse and Tidymodels"
session: 14
author: W. Jake Thompson
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: ["default", "assets/css/my-theme.css", "assets/css/my-fonts.css"]
    seal: false 
    lib_dir: libs
    nature:
      # autoplay: 5000
      highlightStyle: solarized-light
      highlightLanguage: ["r", "css", "yaml"]
      slideNumberFormat: "" 
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      beforeInit: "https://platform.twitter.com/widgets.js"
    includes:
      in_header: [assets/header.html]
params:
  site_link: "https://bit.ly/tidyds-2021"
  class_link: "https://tidyds-2021.wjakethompson.com"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(collapse = TRUE,
                      fig.retina = 3,
                      fig.path = "images/tuning/plots/",
                      fig.align = "center",
                      fig.asp = 0.618,
                      comment = "#>")

xaringanExtra::use_share_again()
xaringanExtra::use_panelset()
xaringanExtra::use_extra_styles(hover_code_line = TRUE,
                                mute_unhighlighted_code = FALSE)
xaringanExtra::use_scribble(pen_color = "#009FB7")

yt_counter <- 0
library(countdown)
library(tidyverse)
library(tidymodels)
library(flair)
library(here)
library(knitr)
library(downlit)
library(vip)
library(themis)

library(xaringancolor)
blue <- "#009FB7"
light_blue <- "#0ADEFF"
yellow <- "#FED766"
dark_yellow <- "#A27A01"
pink <- "#CB297B"
light_pink <- "#FF8DC6"
green <- "#5FAD56"
dark_green <- "#3C6E35"
grey <- "#696773"

library(AmesHousing)
ames <- make_ames()

lm_spec <- 
  linear_reg() %>% 
  set_engine("lm") %>% 
  set_mode("regression")

set.seed(100) # Important!
ames_split  <- initial_split(ames)
ames_train  <- training(ames_split)
ames_test   <- testing(ames_split)

# for figures
splits_pal <- c(blue, yellow, green)

set.seed(100)
cv_folds <- 
    vfold_cv(ames, v= 10, strata = Sale_Price, breaks = 4)

theme_set(wjake::theme_wjake(base_family = "Source Sans Pro",
                             base_size = 14,
                             axis_title_size = 12))
```


class: title-slide, center

<span class="fa-stack fa-4x">
  <i class="fa fa-circle fa-stack-2x" style="color: #ffffff;"></i>
  <strong class="fa-stack-1x" style="color:#009FB7;">`r rmarkdown::metadata$session`</strong>
</span> 

# `r rmarkdown::metadata$title`

## `r rmarkdown::metadata$subtitle`

### `r rmarkdown::metadata$author`

#### [`r params$class_link`](`r params$class_link`) &#183; [`r params$site_link`](`r params$site_link`)

.footer-license[*Tidy Data Science with the Tidyverse and Tidymodels* is licensed under a [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/).]

<div style = "position:fixed; visibility: hidden">
  $$\require{color}\definecolor{blue}{rgb}{0, 0.623529411764706, 0.717647058823529}$$
  $$\require{color}\definecolor{light_blue}{rgb}{0.0392156862745098, 0.870588235294118, 1}$$
  $$\require{color}\definecolor{yellow}{rgb}{0.996078431372549, 0.843137254901961, 0.4}$$
  $$\require{color}\definecolor{dark_yellow}{rgb}{0.635294117647059, 0.47843137254902, 0.00392156862745098}$$
  $$\require{color}\definecolor{pink}{rgb}{0.796078431372549, 0.16078431372549, 0.482352941176471}$$
  $$\require{color}\definecolor{light_pink}{rgb}{1, 0.552941176470588, 0.776470588235294}$$
  $$\require{color}\definecolor{grey}{rgb}{0.411764705882353, 0.403921568627451, 0.450980392156863}$$
</div>
  
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      Macros: {
        blue: ["{\\color{blue}{#1}}", 1],
        light_blue: ["{\\color{light_blue}{#1}}", 1],
        yellow: ["{\\color{yellow}{#1}}", 1],
        dark_yellow: ["{\\color{dark_yellow}{#1}}", 1],
        pink: ["{\\color{pink}{#1}}", 1],
        light_pink: ["{\\color{light_pink}{#1}}", 1],
        grey: ["{\\color{grey}{#1}}", 1]
      },
      loader: {load: ['[tex]/color']},
      tex: {packages: {'[+]': ['color']}}
    }
  });
</script>

---
class: your-turn

# Your Turn 0

.big[
* Open the R Notebook **materials/exercises/14-tuning.Rmd**
* Run the setup chunk
]

```{r yt-setwd-cd, echo = FALSE}
countdown(minutes = 1, seconds = 0,
          font_size = "2em",
          color_border = yellow,
          color_background = blue,
          color_text = yellow,
          color_running_background = "#F0F0F0",
          color_running_text = blue,
          color_finished_background = yellow,
          color_finished_text = blue)
```

---
<div class="hex-book">
  <a href="https://tune.tidymodels.org">
    <img class="hex" src="images/hex/tune.png">
  </a>
  <a href="https://www.tmwr.org/tuning.html">
    <img class="book" src="images/books/tmwr-tuning.png">
  </a>
</div>

---
class: center middle inverse

# KNN

---
# `nearest_neighbor()`

Specifies a model that uses K Nearest Neighbors

```{r eval = FALSE}
nearest_neighbor(neighbors = 1)
```

--

k = .display[neighbors] (PLURAL)

--

.footnote[regression and classification modes]

---
class: your-turn

# Your Turn `r (yt_counter <- yt_counter + 1)`

Here's a new recipe (also in your .Rmd)...

```{r normalize-rec}
normalize_rec <-
  recipe(Sale_Price ~ ., data = ames) %>% 
    step_novel(all_nominal()) %>% 
    step_dummy(all_nominal()) %>% 
    step_zv(all_predictors()) %>% 
    step_center(all_predictors()) %>% 
    step_scale(all_predictors())
```

---
class: your-turn

# Your Turn `r yt_counter`

...and a new model. Can you tell what type of model this is?

```{r knn-spec}
knn5_spec <- 
  nearest_neighbor(neighbors = 5) %>% 
  set_engine("kknn") %>% 
  set_mode("regression")
```

```{r echo = FALSE}
countdown(minutes = 1)
```

---
class: your-turn

# Your Turn `r yt_counter`

Combine the recipe and model into a new workflow named `knn_wf`. Fit the workflow to `cv_folds` and collect its RMSE.

```{r echo = FALSE}
countdown(minutes = 5)
```

---
class: your-turn

```{r yt-knn5-sol, cache = TRUE}
knn5_wf <-
  workflow() %>%
  add_recipe(normalize_rec) %>%
  add_model(knn5_spec)

knn5_wf %>%
  fit_resamples(resamples = cv_folds) %>%
  collect_metrics()
```

---
class: your-turn

# Your Turn `r (yt_counter <- yt_counter + 1)`

Repeat the process in Your Turn 1 with a similar workflow that uses `neighbors = 10`. Does the RMSE change?

```{r echo = FALSE}
countdown(minutes = 5)
```

---
class: your-turn

```{r yt-knn10-sol, cache = TRUE}
knn10_spec <- nearest_neighbor(neighbors = 10) %>% 
    set_engine("kknn") %>% 
    set_mode("regression")

knn10_wf <- 
  knn5_wf %>% 
  update_model(knn10_spec)

knn10_wf %>%
  fit_resamples(resamples = cv_folds) %>% 
  collect_metrics()
```

---
class: pop-quiz

# Pop quiz!

How can you find the best value of `neighbors`/`k`?

--

Compare all the separate values/models

---
class: center middle inverse

# `tune_grid()`

---
# tune 

Functions for fitting and tuning models

<https://tune.tidymodels.org/>

```{r echo=FALSE, out.width="100%"}
knitr::include_url("https://tune.tidymodels.org/")
```

---
# `tune()`

A placeholder for hyper-parameters to be "tuned"

```{r eval = FALSE}
nearest_neighbor(neighbors = tune())
```

---
# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.

.pull-left[
```{r eval = FALSE}
tune_grid(
  object,
  resamples,
  ...,
  grid = 10,
  metrics = NULL,
  control = control_grid()
)
```
]

---
# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.

.pull-left[
```{r eval = FALSE}
tune_grid(
  object, #<<
  resamples,
  ...,
  grid = 10,
  metrics = NULL,
  control = control_grid()
)
```
]

--
 
.pull-right[
One of:

* a `workflow`
* a formula
* a `recipe`
] 

---
# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.

.pull-left[
```{r eval = FALSE}
tune_grid(
  object, #<<
  preprocessor, #<<
  resamples,
  ...,
  grid = 10,
  metrics = NULL,
  control = control_grid()
)
```
]
 
.pull-right[
One of:

* formula + `model`
* `recipe` + `model`
] 

---
# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.

.pull-left[
```{r eval = FALSE}
tune_grid(
  object,
  resamples,
  ...,
  grid = 10, #<<
  metrics = NULL,
  control = control_grid()
)
```
]

.pull-right[
One of:

* A positive integer
* A data frame of tuning combinations
] 

---
# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.

.pull-left[
```{r eval = FALSE}
tune_grid(
  object,
  resamples,
  ...,
  grid = 10, #<<
  metrics = NULL,
  control = control_grid()
)
```
]

.pull-right[
Number of candidate parameter sets to be created automatically.
]

---
# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.

.pull-left[
```{r eval = FALSE}
tune_grid(
  object,
  resamples,
  ...,
  grid = 10, #<<
  metrics = NULL,
  control = control_grid()
)
```
]

.pull-right[
A data frame of tuning combinations.
]

---
# `expand_grid()`

Takes one or more vectors, and returns a data frame holding all combinations of their values.

```{r}
expand_grid(neighbors = c(1,2), foo = 3:5)
```

--

.footnote[tidyr package; see also base `expand.grid()`]

---
class: your-turn

# Your Turn `r (yt_counter <- yt_counter + 1)`

Use `expand_grid()` to create a grid of values for neighbors that spans from 10 to 20. Save the result as `k10_20`.

```{r echo=FALSE}
countdown(minutes = 2)
```

---
class: your-turn

```{r}
k10_20 <- expand_grid(neighbors = 10:20)
k10_20
```

---
class: your-turn

# Your Turn `r (yt_counter <- yt_counter + 1)`

Create a knn workflow that tunes over `neighbors` and uses your `normalize_rec` recipe.

Then use `tune_grid()`, `cv_folds` and `k10_20` to find the best value of neighbors. 

Save the output of `tune_grid()` as `knn_results`.

```{r echo=FALSE}
countdown(minutes = 5)
```

---
class: your-turn

.panelset[
.panel[.panel-name[Code]
```{r yt-knn-tune-sol, cache = TRUE, results='hide'}
knn_tuner <- 
  nearest_neighbor(neighbors = tune()) %>% 
  set_engine("kknn") %>% 
  set_mode("regression")

knn_twf <-
  workflow() %>% 
  add_recipe(normalize_rec) %>% 
  add_model(knn_tuner)

knn_results <- 
  knn_twf %>%
  tune_grid(resamples = cv_folds, 
            grid = k10_20) 

knn_results %>% 
  collect_metrics() %>% 
  filter(.metric == "rmse")
```
]

.panel[.panel-name[Metrics]
```{r}
knn_results %>% 
  collect_metrics() %>% 
  filter(.metric == "rmse")
```
]
]

---
name: show-best

# `show_best()`

Shows the .display[n] most optimum combinations of hyper-parameters

```{r show-best, results='hide'}
knn_results %>% 
  show_best(metric = "rmse", n = 5)
```

---
template: show-best

```{r ref.label='show-best', echo=FALSE}
```

---
# `autoplot()`

.panelset[
```{r knn-plot, panelset = c(source = "Code", output = "Plot"), out.width = "70%"}
knn_results %>% autoplot()
```
]

???

Quickly visualize tuning results

---
class: center middle inverse

# You can tune models *and* recipes

---
class: your-turn

# Your Turn `r (yt_counter <- yt_counter + 1)`

Modify our PCA workflow provided to find the best value for `num_comp` on the grid provided. Which is it? Use `show_best()` to see. Save the output of the fit function as `pca_results`.


```{r echo=FALSE}
countdown(minutes = 5)
```

---
class: your-turn

.panelset[
.panel[.panel-name[Workflow]
```{r pca-sol-wf, results='hide'}
pca_tuner <- recipe(Sale_Price ~ ., data = ames) %>%
    step_novel(all_nominal()) %>%
    step_dummy(all_nominal()) %>%
    step_zv(all_predictors()) %>%
    step_center(all_predictors()) %>%
    step_scale(all_predictors()) %>%
    step_pca(all_predictors(), num_comp = tune()) #<<

pca_twf <- workflow() %>% 
    add_recipe(pca_tuner) %>% 
    add_model(lm_spec)
```
]

.panel[.panel-name[Tuning]
```{r pca-sol-results, cache = TRUE}
nc10_40 <- expand_grid(num_comp = c(10,20,30,40))

pca_results <- pca_twf %>% 
    tune_grid(resamples = cv_folds, grid = nc10_40)

pca_results %>%
  show_best(metric = "rmse")
```
]
]

---
```{r}
library(modeldata)
data(stackoverflow)

# split the data
set.seed(100) # Important!
so_split <- initial_split(stackoverflow, strata = Remote)
so_train <- training(so_split)
so_test <- testing(so_split)

set.seed(100) # Important!
so_folds <- vfold_cv(so_train, v = 10, strata = Remote)
```

---
class: your-turn

# Your Turn `r (yt_counter <- yt_counter + 1)`

Here's a new recipe (also in your .Rmd)...

```{r}
so_rec <- recipe(Remote ~ ., data = so_train) %>% 
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  step_lincomb(all_predictors()) %>% 
  step_downsample(Remote)
```

---
class: your-turn

# Your Turn `r yt_counter`

...and a new model plus workflow. Can you tell what type of model this is?

```{r}
rf_spec <- 
  rand_forest() %>% 
  set_engine("ranger") %>% 
  set_mode("classification")

rf_wf <-
  workflow() %>% 
  add_recipe(so_rec) %>% 
  add_model(rf_spec)
```

---
class: your-turn

# Your Turn `r yt_counter`

Here is the output from `fit_resamples()`...

```{r yt-so-rf-resamples, cache = TRUE}
rf_results <-
  rf_wf %>% 
  fit_resamples(resamples = so_folds,
                metrics = metric_set(roc_auc))

rf_results %>% 
  collect_metrics(summarize = TRUE)
```

---
class: your-turn

# Your Turn `r yt_counter`

Edit the random forest model to tune the `mtry` and `min_n` hyper-parameters; call the new model spec `rf_tuner`. 

Update the model for your workflow; save it as `rf_twf`.

Tune the workflow to `so_folds` and show the best combination of hyper-parameters to maximize `roc_auc`. 

How does it compare to the average ROC AUC across folds from `fit_resamples()`?

```{r echo=FALSE}
countdown(minutes = 10)
```

---
class: your-turn

.panelset[
.panel[.panel-name[Tuning]
```{r yt-so-rf-tune, cache = TRUE, results='hide', messages = FALSE, warning = FALSE}
rf_tuner <- 
  rand_forest(mtry = tune(),
              min_n = tune()) %>% 
    set_engine("ranger") %>% 
    set_mode("classification")

rf_twf <-
  rf_wf %>% 
    update_model(rf_tuner)

rf_twf_results <-
  rf_twf %>% 
    tune_grid(resamples = so_folds,
              metrics = metric_set(roc_auc))
```
]

.panel[.panel-name[Metrics]
```{r}
rf_twf_results %>%
  collect_metrics()
```
]
]

???

defaults:

`mtry` = sqrt(# predictors) = sqrt(20) = `r floor(sqrt(20))`

`min_n` = 1

roc_auc = .702

---
class: center middle inverse

# What next?

---
# `show_best()`

Shows the `n` most optimum combinations of hyper-parameters.

```{r}
rf_twf_results %>%
  show_best(metric = "roc_auc")
```

---
name: select-best

# `select_best()`

Shows the .display[top] combination of hyper-parameters.

```{r select-best, results = "hide"}
so_best <-
  rf_twf_results %>%
  select_best(metric = "roc_auc")

so_best
```

---
template: select-best

```{r ref.label="select-best", echo = FALSE}
```

---
# `finalize_workflow()`

Replaces `tune()` placeholders in a model/recipe/workflow with a set of hyper-parameter values.

```{r}
so_wfl_final <- 
  rf_twf %>%
  finalize_workflow(so_best) #<<
```

---
class: center middle

# The test set

Remember me?

---
# `fit()` and `predict()`

Remember me?

```{r results ='hide'}
so_test_results <-
  so_wfl_final %>%
  fit(data = so_train)

predict(so_test_results, new_data = so_test, type = "class")
predict(so_test_results, new_data = so_test, type = "prob")
```

---
name: last-fit

# `last_fit()`

A better way.

```{r last-fit, results='hide'}
so_test_results <-
  so_wfl_final %>%
  last_fit(so_split) #<<
```

---
template: last-fit

```{r echo = FALSE}
so_test_results
```

---
class: your-turn

# Your Turn `r (yt_counter <- yt_counter + 1)`

Use `select_best()`, `finalize_workflow()`, and `last_fit()` to take the best combination of hyper-parameters from `rf_results` and use them to predict the test set.

How does our actual test ROC AUC compare to our cross-validated estimate?

```{r echo=FALSE}
countdown(minutes = 5)
```

---
class: your-turn

```{r}
so_best <-
  rf_twf_results %>%
  select_best(metric = "roc_auc")

so_wfl_final <-
  rf_twf %>%
  finalize_workflow(so_best)

so_test_results <-
  so_wfl_final %>%
  last_fit(split = so_split)

so_test_results %>%
  collect_metrics()
```

---
# Comparing performance

**Resampling**
```{r echo = FALSE}
rf_twf_results %>%
  show_best(metric = "roc_auc", n = 1)
```

--

**Test Set**
```{r echo = FALSE}
so_test_results %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc")
```

???

Ideally, performance estimated from resampling should be similar to what is seen in the test set. If performance from resampling higher, there may be concerns about overfitting.

---
class: center middle inverse

# final final final

---
# Final metrics

```{r}
so_test_results %>%
  collect_metrics()
```

---
# Predict the test set

```{r}
so_test_results %>%
  collect_predictions()
```

---
.panelset[
.panel[.panel-name[Code]
```{r so-roc, fig.show='hide'}
roc_values <-
  so_test_results %>%
  collect_predictions() %>%
  roc_curve(truth = Remote, estimate = .pred_Remote)

autoplot(roc_values)
```
]

.panel[.panel-name[Plot]
```{r show-roc, ref.label="so-roc", echo = FALSE, out.width = "50%", fig.asp = NA}
```
]
]

---
class: title-slide, center

# `r rmarkdown::metadata$title`

```{r closing-hex, echo = FALSE, out.width = "20%"}
include_graphics("images/hex/tune.png")
```

## `r rmarkdown::metadata$subtitle`

### `r rmarkdown::metadata$author`

#### [`r params$class_link`](`r params$class_link`) &#183; [`r params$site_link`](`r params$site_link`)

.footer-license[*Tidy Data Science with the Tidyverse and Tidymodels* is licensed under a [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/).]
